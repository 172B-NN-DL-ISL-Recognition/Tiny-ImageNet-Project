{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy torch torchvision pytorch-ignite tensorboardX tensorboard opendatasets efficientnet-pytorch"
      ],
      "metadata": {
        "id": "h9dN-9_ZtaEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ignite -c pytorch"
      ],
      "metadata": {
        "id": "q_Ap_I-PtccW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opendatasets --upgrade"
      ],
      "metadata": {
        "id": "dnlHI5sMte4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow numpy matplotlib"
      ],
      "metadata": {
        "id": "fv9h-YqFsHrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "8BZDFVjOsXHg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime as dt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import transforms as T\n",
        "from torchvision import models, datasets\n",
        "\n",
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy, Loss, Precision, Recall\n",
        "from ignite.handlers import LRScheduler, ModelCheckpoint, global_step_from_engine\n",
        "from ignite.contrib.handlers import ProgressBar, TensorboardLogger\n",
        "import ignite.contrib.engines.common as common\n",
        "\n",
        "import opendatasets as od\n",
        "import os\n",
        "from random import randint\n",
        "import urllib\n",
        "import zipfile\n",
        "\n",
        "# import warnings\n",
        "import warnings\n",
        "# filter warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "YIJYSjTat31k"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "metadata": {
        "id": "F--tqm5IsxTd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip"
      ],
      "metadata": {
        "id": "KlWFukTdsx8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq 'tiny-imagenet-200.zip'"
      ],
      "metadata": {
        "id": "-dwSGyv0tBhd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = 'tiny-imagenet-200'\n",
        "train_dir = os.path.join(DATA_DIR, 'train') \n",
        "val_dir = os.path.join(DATA_DIR, 'val')\n",
        "test_dir = os.path.join(DATA_DIR, 'test')"
      ],
      "metadata": {
        "id": "AIj9fkz3s-9R"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset using the Keras ImageDataGenerator\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Define the batch size and target image size\n",
        "batch_size = 32\n",
        "target_size = (64, 64)\n",
        "\n",
        "# Load the training data\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the validation data\n",
        "val_data = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the test data\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Olxmz2crsa1V",
        "outputId": "03429d0e-a3ba-4281-b9ba-0bab1bd379e8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 1 classes.\n",
            "Found 10000 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', \n",
        "                           input_shape=(64, 64, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(200, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "J1IrcoANsky-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "history = model.fit(train_data, epochs=epochs, validation_data=val_data)"
      ],
      "metadata": {
        "id": "jXyhDpKIsllH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "746f365e-241a-4cc6-c0d2-7b2d9e2cbb51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3125/3125 [==============================] - 546s 174ms/step - loss: 4.4482 - accuracy: 0.0912 - val_loss: 1469.5253 - val_accuracy: 0.0029\n",
            "Epoch 2/10\n",
            "3125/3125 [==============================] - 549s 176ms/step - loss: 3.5568 - accuracy: 0.2140 - val_loss: 1550.1479 - val_accuracy: 0.0054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "fQmF4scMryFx",
        "outputId": "91dce7d1-4433-4641-9f3f-4bf9aedd9111"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-03009d8354b8>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtiny_imagenet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'tiny_imagenet' from 'keras.datasets' (/usr/local/lib/python3.10/dist-packages/keras/datasets/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.datasets import tiny_imagenet\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Load the Tiny ImageNet dataset\n",
        "(x_train, y_train), (x_test, y_test) = tiny_imagenet.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(64, 64, 3)))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(200, activation='softmax'))\n",
        "\n",
        "# Train the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    }
  ]
}